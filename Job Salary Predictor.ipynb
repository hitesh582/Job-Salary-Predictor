{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import GradientBoostingRegressor  # Change to GradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('job_salary_datasetnew.csv')  # Replace 'job_salary_dataset.csv' with your dataset filename\n",
        "# Explore the dataset\n",
        "print(data.head())\n",
        "\n",
        "# Split dataset into features (X) and target variable (y)\n",
        "X = data[['job_description', 'experience_years', 'education_level', 'location']]\n",
        "y = data['salary']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define preprocessing steps for textual data and numerical/categorical data\n",
        "text_preprocessor = TfidfVectorizer()\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# Define which columns should be treated as numerical or categorical\n",
        "numeric_features = ['experience_years']\n",
        "categorical_features = ['education_level', 'location']\n",
        "\n",
        "# Create a preprocessing transformer to handle different types of features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_preprocessor, 'job_description'),\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Define the model (change to GradientBoostingRegressor)\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "# Create a pipeline for preprocessing and model training\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', model)\n",
        "])\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'model__n_estimators': [100, 200, 300],\n",
        "    'model__learning_rate': [0.05, 0.1, 0.2],  # Add learning rate hyperparameter\n",
        "    'model__max_depth': [3, 5, 7]  # Add max_depth hyperparameter\n",
        "}\n",
        "\n",
        "# Perform grid search cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = -grid_search.best_score_\n",
        "\n",
        "# Update the pipeline with the best parameters\n",
        "pipeline.set_params(**best_params)\n",
        "\n",
        "# Fit the pipeline to the training data with the updated parameters\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('Mean Absolute Error:', mae)\n",
        "\n",
        "# Calculate the average salary in the dataset\n",
        "average_salary = data['salary'].mean()\n",
        "\n",
        "# Calculate the mean absolute error in terms of percentage of the average salary\n",
        "mae_percentage = (mae / average_salary) * 100\n",
        "\n",
        "# Calculate the accuracy as the complement of the MAE percentage\n",
        "accuracy_percentage = 100 - mae_percentage\n",
        "\n",
        "print('Model Accuracy:', round(accuracy_percentage, 2), '%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCGWkLpqPBpL",
        "outputId": "fae638cc-0ab6-4e0f-c28d-49ade4581322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     job_description  salary  \\\n",
            "0  Software Engineer position requires expertise ...   80000   \n",
            "1  Marketing Specialist responsible for developin...   60000   \n",
            "2  Data Analyst role involves analyzing large dat...   70000   \n",
            "3  Graphic Designer with proficiency in Adobe Cre...   55000   \n",
            "4  Sales Associate responsible for generating lea...   50000   \n",
            "\n",
            "   experience_years    education_level       location  \n",
            "0                 3  Bachelor's Degree  San Francisco  \n",
            "1                 2  Bachelor's Degree       New York  \n",
            "2                 2  Bachelor's Degree        Seattle  \n",
            "3                 2  Bachelor's Degree    Los Angeles  \n",
            "4                 1  Bachelor's Degree        Chicago  \n",
            "Mean Absolute Error: 8259.781608148656\n",
            "Model Accuracy: 88.48 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}